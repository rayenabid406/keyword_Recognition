# keyword-recognition
keyword-recognition ğŸ¤ ESP32 Voice Command Recognition with TensorFlow Lite A high-performance voice command recognition system for ESP32 microcontrollers using TensorFlow Lite Micro. Recognizes "on" and "off" commands with 79% accuracy using a lightweight convolutional neural network (CNN). -Used my own recorded DataSet using audacity and exported it to mano .wav format in 16khz.  âœ¨ Features Real-time Audio Processing: 16kHz sampling rate with I2S microphone  TensorFlow Lite Micro: Ultra-lightweight neural network inference  79% Accuracy: Optimized CNN model for limited hardware  Low Latency: ~100ms inference time on ESP32  Memory Efficient: Only 15KB model size, 40KB RAM usage  PlatformIO Ready: Easy build and deployment  ğŸ“Š Performance Metric Value Model Accuracy 79% Model Size 15.36 KB RAM Usage 40 KB Inference Time ~100 ms Sampling Rate 16 kHz Audio Window 1 second (16000 samples) ğŸ› ï¸ Hardware Requirements ESP32 Dev Board (ESP32-WROOM-32)  I2S Microphone (INMP441 )  3.3V Power Supply  Jumper Wires  Wiring Diagram text ESP32 I2S Microphone (INMP441)  3.3V ----> VDD GND ----> GND GPIO32 ----> L/R (GND for left channel) GPIO33 ----> WS (Word Select/LRCLK) GPIO25 ----> SCK (BCLK) GPIO26 ----> SD (DOUT)  ğŸš€ Quick Start  Install PlatformIO bash Install PlatformIO extension in VSCode Or via pip: pip install platformio 2. Clone and Build bash git clone https://github.com/yourusername/esp32-voice-commands.git cd esp32-voice-commands pio run 3. Upload to ESP32 bash pio run --target upload 4. Monitor Output bash pio device monitor ğŸ§  Model Architecture The neural network is optimized for ESP32 hardware constraints:  text Input: [16000] audio samples â†“ Reshape: [100, 160, 1] â†“ Conv1D: 8 filters, kernel=3, stride=2 â†’ [50, 80, 8] â†“ Conv1D: 16 filters, kernel=3, stride=2 â†’ [25, 40, 16] â†“ Conv1D: 32 filters, kernel=3, stride=2 â†’ [13, 20, 32] â†“ Global Average Pooling â†“ Dense: 3 units (softmax) â†“ Output: [none, on, off] probabilities ğŸ”§ Training Your Own Model  Prepare Dataset python Record audio samples python data/training_scripts/record_dataset.py  Expected structure: data/ â”œâ”€â”€ none/ # Background noise â”œâ”€â”€ on/ # "on" commands â””â”€â”€ off/ # "off" commands Train Model python python data/training_scripts/train_model.py Outputs: - model.tflite (optimized for ESP32) - model.h (C header file) Convert for ESP32 python python data/training_scripts/convert_model.py model.tflite Generates model_data.cc for embedding âš™ï¸ Configuration PlatformIO Settings (platformio.ini) ini [env:esp32dev] platform = espressif32 board = esp32dev framework = arduino lib_deps = tensorflow/lite@^2.14.0 build_flags = -Wno-error=maybe-uninitialized Audio Configuration cpp // Adjust in main.cpp #define SAMPLE_RATE 16000 #define SAMPLE_DURATION 1000 // milliseconds #define AUDIO_BUFFER_SIZE 16000 ğŸ“ˆ Performance Optimization Tips Reduce Input Size: Try 8000 samples (0.5s) for faster inference  Simplify Model: Reduce filters in Conv1D layers  Quantization: Use int8 quantization for 2-3x speedup  Pruning: Remove less important weights  CPU Frequency: Increase to 240MHz for faster inference  ğŸ§ª Testing Unit Tests bash pio test -e native Performance Benchmark cpp // Enable in main.cpp #define BENCHMARK_INFERENCE true // Output: Inference time, memory usage, accuracy ğŸ” Debugging Common Issues & Solutions Issue Solution "Tensor allocation failed" Increase tensor_arena size in NeuralNetwork.h Poor accuracy Retrain with more diverse data Audio clipping Adjust microphone gain in code High latency Reduce AUDIO_BUFFER_SIZE Memory overflow Enable PSRAM if available Serial Debug Output text === ESP32 VOICE COMMAND SYSTEM === Model: 79% accuracy I2S initialized âœ… Tensor arena is 16-byte aligned âœ… Network ready! Listening... (say "on" or "off") Prediction: [0.02, 0.85, 0.13] -> "on" Inference time: 94ms ğŸ“š API Reference NeuralNetwork Class cpp class NeuralNetwork { public: bool begin(); // Initialize model void predict(); // Run inference float* getInputBuffer(); // Get audio input buffer float* getOutputBuffer(); // Get predictions [none, on, off] int getInputSize(); // Returns 16000 int getOutputSize(); // Returns 3 }; Training Result : â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“ â”ƒ Layer (type) â”ƒ Output Shape â”ƒ Param # â”ƒ â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”© â”‚ conv1d (Conv1D) â”‚ (None, 15988, 8) â”‚ 112 â”‚ â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”‚ max_pooling1d (MaxPooling1D) â”‚ (None, 3997, 8) â”‚ 0 â”‚ â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”‚ conv1d_1 (Conv1D) â”‚ (None, 3989, 16) â”‚ 1,168 â”‚ â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”‚ max_pooling1d_1 (MaxPooling1D) â”‚ (None, 997, 16) â”‚ 0 â”‚ â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”‚ conv1d_2 (Conv1D) â”‚ (None, 991, 32) â”‚ 3,616 â”‚ â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”‚ max_pooling1d_2 (MaxPooling1D) â”‚ (None, 247, 32) â”‚ 0 â”‚ â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”‚ global_average_pooling1d â”‚ (None, 32) â”‚ 0 â”‚ â”‚ (GlobalAveragePooling1D) â”‚ â”‚ â”‚ â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”‚ dense (Dense) â”‚ (None, 16) â”‚ 528 â”‚ â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”‚ dense_1 (Dense) â”‚ (None, 3) â”‚ 51 â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ Total params: 5,475 (21.39 KB) Trainable params: 5,475 (21.39 KB) Non-trainable params: 0 (0.00 B) Epoch 1/30 6/6 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1s 46ms/step - accuracy: 0.3489 - loss: 1.0935 - val_accuracy: 0.3478 - val_loss: 1.0870 Epoch 2/30 6/6 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 19ms/step - accuracy: 0.3889 - loss: 1.0809 - val_accuracy: 0.3478 - val_loss: 1.0748 Epoch 3/30 6/6 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 15ms/step - accuracy: 0.3699 - loss: 1.0636 - val_accuracy: 0.3478 - val_loss: 1.0561 Epoch 4/30 6/6 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 14ms/step - accuracy: 0.3488 - loss: 1.0436 - val_accuracy: 0.3478 - val_loss: 1.0295 Epoch 5/30 6/6 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 14ms/step - accuracy: 0.3368 - loss: 1.0063 - val_accuracy: 0.3043 - val_loss: 0.9922 Epoch 6/30 6/6 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 14ms/step - accuracy: 0.3801 - loss: 0.9515 - val_accuracy: 0.5652 - val_loss: 0.9472 Epoch 7/30 6/6 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 15ms/step - accuracy: 0.6957 - loss: 0.9033 - val_accuracy: 0.5652 - val_loss: 0.9058 Epoch 8/30 6/6 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 14ms/step - accuracy: 0.6838 - loss: 0.8473 - val_accuracy: 0.5652 - val_loss: 0.8745 Epoch 9/30 6/6 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 15ms/step - accuracy: 0.6827 - loss: 0.8211 - val_accuracy: 0.5652 - val_loss: 0.8547 Epoch 10/30 6/6 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 14ms/step - accuracy: 0.6698 - loss: 0.7945 - val_accuracy: 0.5652 - val_loss: 0.8411 Epoch 11/30 6/6 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 15ms/step - accuracy: 0.7095 - loss: 0.7803 - val_accuracy: 0.5652 - val_loss: 0.8289 Epoch 12/30 6/6 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 15ms/step - accuracy: 0.6740 - loss: 0.7490 - val_accuracy: 0.5652 - val_loss: 0.8143 Epoch 13/30 6/6 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 14ms/step - accuracy: 0.6653 - loss: 0.7355 - val_accuracy: 0.5652 - val_loss: 0.7989 Epoch 14/30 6/6 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 14ms/step - accuracy: 0.6862 - loss: 0.7249 - val_accuracy: 0.5652 - val_loss: 0.7892 Epoch 15/30 6/6 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 14ms/step - accuracy: 0.6445 - loss: 0.7132 - val_accuracy: 0.5652 - val_loss: 0.7740 Epoch 16/30 6/6 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 14ms/step - accuracy: 0.7021 - loss: 0.6503 - val_accuracy: 0.5652 - val_loss: 0.7679 Epoch 17/30 6/6 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 15ms/step - accuracy: 0.6155 - loss: 0.6406 - val_accuracy: 0.5652 - val_loss: 0.7551 Epoch 18/30 6/6 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 15ms/step - accuracy: 0.6912 - loss: 0.5988 - val_accuracy: 0.5217 - val_loss: 0.7786 Epoch 19/30 6/6 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 15ms/step - accuracy: 0.6545 - loss: 0.5787 - val_accuracy: 0.5217 - val_loss: 0.7711 Epoch 20/30 6/6 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 14ms/step - accuracy: 0.7423 - loss: 0.5366 - val_accuracy: 0.5652 - val_loss: 0.7798 Epoch 21/30 6/6 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 14ms/step - accuracy: 0.7244 - loss: 0.5255 - val_accuracy: 0.5217 - val_loss: 0.8285 Epoch 22/30 6/6 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 14ms/step - accuracy: 0.6917 - loss: 0.5221 - val_accuracy: 0.6522 - val_loss: 0.8480 Epoch 23/30 6/6 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 15ms/step - accuracy: 0.7372 - loss: 0.5095 - val_accuracy: 0.6957 - val_loss: 0.8122 Epoch 24/30 6/6 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 14ms/step - accuracy: 0.8077 - loss: 0.5080 - val_accuracy: 0.6522 - val_loss: 0.7609 Epoch 25/30 6/6 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 13ms/step - accuracy: 0.7210 - loss: 0.4823 - val_accuracy: 0.5217 - val_loss: 0.7916 Epoch 26/30 6/6 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 14ms/step - accuracy: 0.6209 - loss: 0.5821 - val_accuracy: 0.6087 - val_loss: 0.7633 Epoch 27/30 6/6 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 14ms/step - accuracy: 0.7168 - loss: 0.5159 - val_accuracy: 0.5652 - val_loss: 0.7398 Epoch 28/30 6/6 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 14ms/step - accuracy: 0.6779 - loss: 0.4947 - val_accuracy: 0.6522 - val_loss: 0.7026 Epoch 29/30 6/6 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 14ms/step - accuracy: 0.8183 - loss: 0.4666 - val_accuracy: 0.6087 - val_loss: 0.7239 Epoch 30/30 6/6 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 14ms/step - accuracy: 0.8875 - loss: 0.4579 - val_accuracy: 0.6522 - val_loss: 0.6907 1/1 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 27ms/step - accuracy: 0.7931 - loss: 0.4614  Test Accuracy: 79.31% Updated Working model_data.cc new version Terminal output : === NEW MODEL (79.31% accuracy) === Model: 15360 bytes Allocating tensors... Input size: 16000 Output size: 3 âœ… Network ready!  ğŸ¤ Contributing Fork the repository  Create a feature branch (git checkout -b feature/improvement)  Commit changes (git commit -am 'Add feature')  Push to branch (git push origin feature/improvement)  Create Pull Request  ğŸ“„ License MIT License - see LICENSE file for details.  ğŸ™ Acknowledgments Core Technologies -TensorFlow Lite Micro  -ESP32 Core  -PlatformIO  -ArduinoFFT  Signal Processing Foundations -Cooley-Tukey FFT Algorithm  -Fast Fourier Transform Libraries  ğŸ“ Support  Email: rayen.abid860@gmail.com  â­ If this project helped you, please give it a star! â­
